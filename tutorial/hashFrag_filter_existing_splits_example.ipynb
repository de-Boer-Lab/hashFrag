{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a73c2fec-471c-4bb4-a0b0-2342bea69d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T23:42:38.163871Z",
     "iopub.status.busy": "2025-03-01T23:42:38.163403Z",
     "iopub.status.idle": "2025-03-01T23:42:38.166623Z",
     "shell.execute_reply": "2025-03-01T23:42:38.166265Z",
     "shell.execute_reply.started": "2025-03-01T23:42:38.163847Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['NUMEXPR_MAX_THREADS'] = '16' # just to prevent warning NUMEXPR messages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4f802-44f2-4b67-a2ad-e8fb09365241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T21:03:40.254199Z",
     "iopub.status.busy": "2025-01-10T21:03:40.212327Z",
     "iopub.status.idle": "2025-01-10T21:03:40.436413Z",
     "shell.execute_reply": "2025-01-10T21:03:40.435946Z",
     "shell.execute_reply.started": "2025-01-10T21:03:40.254139Z"
    },
    "tags": []
   },
   "source": [
    "# `help` commands for general usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db2ea46-cdec-4611-afad-96d7eb2a42c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T22:52:05.144623Z",
     "iopub.status.busy": "2025-03-01T22:52:05.144387Z",
     "iopub.status.idle": "2025-03-01T22:52:05.475726Z",
     "shell.execute_reply": "2025-03-01T22:52:05.475178Z",
     "shell.execute_reply.started": "2025-03-01T22:52:05.144601Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: hashFrag [-h]\n",
      "                {blastn_module,blastn_array_module,process_blast_results_module,filter_candidates_module,filter_test_split_module,stratify_test_split_module,identify_homologous_groups_module,create_orthogonal_splits_module,filter_existing_splits,stratify_test_split,create_orthogonal_splits}\n",
      "                ...\n",
      "\n",
      "hashFrag is a tool developed to mitigate the impacts of homology-based data leakage in sequence-to-expression\n",
      "models. By identifying homology (based on pairwise alignment scores) in a sequence dataset, this tool can be used\n",
      "to filter homologous sequences spanning existing train-test splits (e.g., chromosomal splits), stratify a test\n",
      "split according to different levels of homology, or create homology-aware train-test splits.\n",
      "\n",
      "positional arguments:\n",
      "  {blastn_module,blastn_array_module,process_blast_results_module,filter_candidates_module,filter_test_split_module,stratify_test_split_module,identify_homologous_groups_module,create_orthogonal_splits_module,filter_existing_splits,stratify_test_split,create_orthogonal_splits}\n",
      "    blastn_module       A wrapper script calling BLASTn to identify candidate pairs of sequences sharing regions\n",
      "                        with high similarity.\n",
      "    blastn_array_module\n",
      "                        A wrapper script to set up an array job calling BLASTn to identify candidate pairs of\n",
      "                        sequences sharing regions with high similarity.\n",
      "    process_blast_results_module\n",
      "                        A wrapper script calling BLASTn to identify candidate pairs of sequences sharing regions\n",
      "                        with high similarity.\n",
      "    filter_candidates_module\n",
      "                        Filter candidate pairs based on a specified alignment score threshold (false-positive\n",
      "                        removal).\n",
      "    filter_test_split_module\n",
      "                        Filter test sequences that exhibit homology with any train sequences.\n",
      "    stratify_test_split_module\n",
      "                        Stratify the test split into subsplits based on their maximum alignment score to the\n",
      "                        sequences in the train split.\n",
      "    identify_homologous_groups_module\n",
      "                        Identify all distinct groups of homologous sequences.\n",
      "    create_orthogonal_splits_module\n",
      "                        Create homology-aware test-train splits.\n",
      "    filter_existing_splits\n",
      "                        Execute the full workflow of commands to filter homology spanning the input test splits.\n",
      "    stratify_test_split\n",
      "                        Execute the full workflow of commands to stratify the test split based on their maximum\n",
      "                        pairwise alignment score to the train split sequences.\n",
      "    create_orthogonal_splits\n",
      "                        Execute the full workflow of commands to create homology-aware train-test splits.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "hashFrag -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbd36e8-e6cd-4683-8a15-6a0ae4995e19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T22:52:10.478908Z",
     "iopub.status.busy": "2025-03-01T22:52:10.478683Z",
     "iopub.status.idle": "2025-03-01T22:52:10.776650Z",
     "shell.execute_reply": "2025-03-01T22:52:10.776123Z",
     "shell.execute_reply.started": "2025-03-01T22:52:10.478889Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: hashFrag filter_existing_splits [-h] [--train-fasta-path TRAIN_FASTA_PATH]\n",
      "                                       [--test-fasta-path TEST_FASTA_PATH] [-w WORD_SIZE] [-g GAPOPEN]\n",
      "                                       [-x GAPEXTEND] [-p PENALTY] [-r REWARD] [-m MAX_TARGET_SEQS]\n",
      "                                       [--exec-makeblastdb-only] [--skip-revcomp] [--xdrop-ungap XDROP_UNGAP]\n",
      "                                       [--xdrop-gap XDROP_GAP] [--xdrop-gap_final XDROP_GAP_FINAL] [-e EVALUE]\n",
      "                                       [-d DUST] [-b BLASTDB_ARGS] [--blastdb-label BLASTDB_LABEL]\n",
      "                                       [-B BLASTN_ARGS] [-T THREADS] [--force] -t THRESHOLD [-o OUTPUT_DIR]\n",
      "\n",
      "Execute the full workflow of commands to filter homology spanning the input test splits. This involves identifying\n",
      "identifying pairs of sequences sharing similarities with BLAST, filtering candidates based on a specified\n",
      "threshold, and filtering the input test split such that there exist no shared homology between the train and test\n",
      "splits..\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --train-fasta-path TRAIN_FASTA_PATH\n",
      "                        Input FASTA file for the training data split, which will comprise the BLAST database.\n",
      "                        (supports unzipped or gzipped file formats)\n",
      "  --test-fasta-path TEST_FASTA_PATH\n",
      "                        Each sequence will be queried against the train split BLAST database. (supports unzipped\n",
      "                        or gzipped file formats)\n",
      "  -w WORD_SIZE, --word-size WORD_SIZE\n",
      "                        Length of exact matching subsequences of initial match (Default: 11).\n",
      "  -g GAPOPEN, --gapopen GAPOPEN\n",
      "                        Penalty (positive value) for opening gap in the alignment (Default: 2).\n",
      "  -x GAPEXTEND, --gapextend GAPEXTEND\n",
      "                        Penalty (positive value) for extending an existing gap in the alignment (Default: 1).\n",
      "  -p PENALTY, --penalty PENALTY\n",
      "                        Nucleotide mismatch in penalty (negative value) the alignment (Default: -1).\n",
      "  -r REWARD, --reward REWARD\n",
      "                        Nucleotide match reward in the alignment (Default: 1).\n",
      "  -m MAX_TARGET_SEQS, --max-target-seqs MAX_TARGET_SEQS\n",
      "                        The maximum number of target sequences that can be returned per query sequence (Default:\n",
      "                        500).\n",
      "  --exec-makeblastdb-only\n",
      "                        Only run the makeblastdb command (default: False, set to True when specified).\n",
      "  --skip-revcomp        Skip generating reverse complement of sequences comprising the BLAST database (Default:\n",
      "                        False, generated if not skipped).\n",
      "  --xdrop-ungap XDROP_UNGAP\n",
      "                        X-drop threshold for ungapped alignment extension (Permissible values: real numbers;\n",
      "                        Default: 20).\n",
      "  --xdrop-gap XDROP_GAP\n",
      "                        X-drop threshold for gapped alignment extension (Permissible values: real numbers;\n",
      "                        Default: 30).\n",
      "  --xdrop-gap_final XDROP_GAP_FINAL\n",
      "                        X-drop threshold for final alignment extension (Permissible values: real numbers; Default:\n",
      "                        100).\n",
      "  -e EVALUE, --evalue EVALUE\n",
      "                        The likelihood threshold required to report sequences as a match (Default: 10).\n",
      "  -d DUST, --dust DUST  Filter low-complexity (e.g., repetitive) regions (Default: 'no').\n",
      "  -b BLASTDB_ARGS, --blastdb-args BLASTDB_ARGS\n",
      "                        Pass additional arguments for makeblastdb call.\n",
      "  --blastdb-label BLASTDB_LABEL\n",
      "                        A label for the BLAST database.\n",
      "  -B BLASTN_ARGS, --blastn-args BLASTN_ARGS\n",
      "                        Pass additional arguments for blastn call.\n",
      "  -T THREADS, --threads THREADS\n",
      "                        The number of CPUs for database search (Default: 1).\n",
      "  --force               Force overwrite existing BLAST module output files (Default: False, existing output files\n",
      "                        will not be overwritten).\n",
      "  -t THRESHOLD, --threshold THRESHOLD\n",
      "                        Alignment score threshold to discern a pair of sequences as homologous or a false-positive\n",
      "                        candidate.\n",
      "  -o OUTPUT_DIR, --output-dir OUTPUT_DIR\n",
      "                        Directory to write BLASTn results (Default: '.').\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "hashFrag filter_existing_splits -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3707df5-9f13-45e0-a994-8f1723090bec",
   "metadata": {},
   "source": [
    "# Section 0: Introduction\n",
    "\n",
    "> This notebook refers to the case when users have existing train-test splits and are interested in identifying and mitigating data leakage attributed to shared sequence homology across splits.\n",
    "\n",
    "The basic workflow is performed with two data splits from a subsampled MPRA dataset (K562): a 8,000-sequence train split and a 2,000-sequence test split (provided in the `data` directory).\n",
    "\n",
    "This notebook serves a walkthrough of calling the individual modules comprising the `hashFrag filter_existing_splits` command.\n",
    "\n",
    "The call of the complete pipeline(`lightning` mode):\n",
    "\n",
    "```\n",
    "hashFrag filter_existing_splits \\\n",
    "--train-fasta-path ../data/example_train_split.fa \\\n",
    "--test-fasta-path ../data/example_test_split.fa \\\n",
    "--word-size 7 \\\n",
    "--max-target-seqs 8000 \\\n",
    "--evalue 100 \\\n",
    "--threshold 60 \\\n",
    "--force \\\n",
    "--skip-revcomp \\\n",
    "--output-dir ../data/tutorial.filter_existing_splits.work\n",
    "```\n",
    "\n",
    "However, it may be desirable to instead use exact alignment scores (e.g., Smith-Waterman local alignment scores) for the homology search process. This notebook serves as a walkthrough for how users can use manually computed local alignment scores for the BLAST candidate pairs by calling the individual modules comprising the `filter_existing_splits` pipeline.\n",
    "\n",
    "## Section 0.1 - A note on the selected parameters for this tutorial\n",
    "\n",
    "Successful identification of cases of homology is paramount to effectively mitigate homology-based data leakage. As such, we configure the BLASTn parameters such that recall is maximized, even if it comes at the expense of increased false-positives. Here we consider the following parameters of BLASTn:\n",
    "\n",
    "* `word_size`: smaller word sizes results in more exact word matches found between the query and sequences in the database, leading to more alignment score calculations being initialized.\n",
    "* `max_target_seqs`: set to the size of the database to remove any constraints and allow for all possible candidate sequences to be returned for a given query.\n",
    "* `evalue`: the e-value statistic is a measure of how likely you observe the alignment by chance (lower value corresponds to less likely to observe). By increasing the e-value threshold, less stringent matches that could be due to chance are returned.\n",
    "* `dust`: by setting dust off, low-complexity (e.g., repetitive sequences) are no longer masked/filtered out.\n",
    "\n",
    "An alignment score threshold of 60 was determined to be appropriate for a sequence length of 200bp based on analyses assessing alignment scores between dinucleotide shuffled (i.e., random) and genomic nucleotide sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614c9641-55f1-47be-abbc-9359444f0528",
   "metadata": {},
   "source": [
    "# Section 1 - Identifying candidate similar sequences\n",
    "\n",
    "When user-derived train-test splits are provided, comparisons are constrained to pairs of sequences across splits. The process of identifying candidate pairs of similar sequences involves first creating a BLAST database of sequences in the train split, and then querying each test split sequence against the database. The BLASTn algorithm returns pairwise matches that represent potential cases of homology. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9207237f-ac51-4448-b06e-add500743ab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T23:42:52.192927Z",
     "iopub.status.busy": "2025-03-01T23:42:52.192695Z",
     "iopub.status.idle": "2025-03-01T23:44:46.875462Z",
     "shell.execute_reply": "2025-03-01T23:44:46.874893Z",
     "shell.execute_reply.started": "2025-03-01T23:42:52.192909Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-02 08:42:52 - blastn_module - INFO - Calling module...\n",
      "2025-03-02 08:42:52 - blastn_module - INFO - Train and test FASTA files detected. Computing pairwise BLAST comparisons across splits...\n",
      "2025-03-02 08:42:52 - blastn_module - INFO - BLASTn output: \n",
      "\n",
      "Building a new DB, current time: 03/02/2025 08:42:52\n",
      "New DB name:   /rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.filter_existing_splits.work/hashFrag.blastdb\n",
      "New DB title:  hashFrag\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 8000 sequences in 0.116502 seconds.\n",
      "\n",
      "\n",
      "\n",
      "2025-03-02 08:42:52 - blastn_module - INFO - BLAST DataBase construction finished and written to: /rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.filter_existing_splits.work/hashFrag.blastdb\n",
      "2025-03-02 08:44:46 - blastn_module - INFO - BLASTn process finished and written to: /rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.filter_existing_splits.work/example_test_split.blastn.out\n",
      "2025-03-02 08:44:46 - blastn_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "TRAIN_FASTA_PATH=../data/example_train_split.fa\n",
    "TEST_FASTA_PATH=../data/example_test_split.fa\n",
    "WORK_DIR=../data/tutorial.filter_existing_splits.work\n",
    "\n",
    "hashFrag blastn_module \\\n",
    "--train-fasta-path $TRAIN_FASTA_PATH \\\n",
    "--test-fasta-path $TEST_FASTA_PATH \\\n",
    "--word-size 7 \\\n",
    "--max-target-seqs 8000 \\\n",
    "--evalue 100 \\\n",
    "--blastdb-label \"hashFrag\" \\\n",
    "--skip-revcomp \\\n",
    "--output-dir $WORK_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1565bfc6-bd1c-4470-97a3-74609cfd3c2b",
   "metadata": {},
   "source": [
    "## Section 1.1 - Processing the raw `blastn` output file\n",
    "\n",
    "This processing step extracts the top-scoring alignment for each unique query-subject sequence pair and corrects the heuristic alignment score for subsequent steps. The processed tab-delimited file contains 3 columns (query sequence ID, subject sequence ID and their corrected heuristic alignment score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe2011eb-d80d-410f-b3c0-8735df1b9560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T23:44:46.876676Z",
     "iopub.status.busy": "2025-03-01T23:44:46.876494Z",
     "iopub.status.idle": "2025-03-01T23:44:49.823179Z",
     "shell.execute_reply": "2025-03-01T23:44:49.822653Z",
     "shell.execute_reply.started": "2025-03-01T23:44:46.876655Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-02 08:44:49 - process_blast_results_module - INFO - Calling module...\n",
      "2025-03-02 08:44:49 - process_blast_results_module - INFO - Processed BLASTn results written to: ../data/tutorial.filter_existing_splits.work/example_test_split.blastn.processed.tsv\n",
      "2025-03-02 08:44:49 - process_blast_results_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.filter_existing_splits.work\n",
    "LABEL=example_test_split\n",
    "BLASTN_PATH=$WORK_DIR/${LABEL}.blastn.out\n",
    "PROCESSED_BLASTN_PATH=$WORK_DIR/${LABEL}.blastn.processed.tsv\n",
    "\n",
    "hashFrag process_blast_results_module --blastn-path $BLASTN_PATH --processed-blastn-path $PROCESSED_BLASTN_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0430f8b-febe-42d6-b4fd-1441fb122d06",
   "metadata": {},
   "source": [
    "# Section 2: Filter false-positives based on a defined threshold\n",
    "\n",
    "The next step involves filtering candidate pairings with alignment scores lower than the specified threshold. There are two different modes of hashFrag depending on what alignment score is selected.\n",
    "\n",
    "1. `hashFrag-lightning` is the faster version where the alignment score computed from the BLAST output file. BLASTn is a heuristic method and the alignment scores were found to highly correlate with the optimal alignment scores; however, its underestimation of moderate levels of homology leads to slightly lower recall. \n",
    "\n",
    "The following call performs the default behavior:\n",
    "\n",
    "```\n",
    "WORK_DIR=../data/tutorial.filter_existing_splits.work\n",
    "INPUT_PATH=$WORK_DIR/hashFrag.blastn.out\n",
    "hashFrag filter_candidates_module -i $INPUT_PATH -t 60 -o $WORK_DIR\n",
    "```\n",
    "\n",
    "2. `hashFrag-pure` is the slower but more comprehensive method that is based on the optimal, Smith-Waterman local alignment scores between pairs of sequences. The calculation of optimal alignment scores incurs an additional cost to filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752b145-0e01-4cb4-8db9-a5ad61d38eaa",
   "metadata": {},
   "source": [
    "## Section 2.1: hashFrag-pure mode\n",
    "\n",
    "To limit memory usage, we'll start by partitioning the blast output file based on size. \n",
    "\n",
    "After completion of this step, all downstream steps will now be based on the homology identified using the exact alignment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6770fdb3-eb7f-4f2b-a902-4d04c212bfdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T23:44:49.824003Z",
     "iopub.status.busy": "2025-03-01T23:44:49.823835Z",
     "iopub.status.idle": "2025-03-01T23:44:49.873288Z",
     "shell.execute_reply": "2025-03-01T23:44:49.872837Z",
     "shell.execute_reply.started": "2025-03-01T23:44:49.823983Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1.5K\n",
      "-rw-r----- 1 brett 1.4M Mar  2 08:44 example_test_split.blastn.processed.partition_aaac.tsv\n",
      "-rw-r----- 1 brett 3.2M Mar  2 08:44 example_test_split.blastn.processed.partition_aaab.tsv\n",
      "-rw-r----- 1 brett 3.2M Mar  2 08:44 example_test_split.blastn.processed.partition_aaaa.tsv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.filter_existing_splits.work\n",
    "\n",
    "cd $WORK_DIR\n",
    "PROCESSED_BLASTN_PATH=$PWD/example_test_split.blastn.processed.tsv\n",
    "BLAST_DIR=$PWD/blast_partitions\n",
    "LABEL=$( basename -s \".tsv\" $PROCESSED_BLASTN_PATH )\n",
    "\n",
    "# Create directory for partitioned processed BLAST file\n",
    "mkdir -p $BLAST_DIR\n",
    "cd $BLAST_DIR\n",
    "\n",
    "# Split the file based on number of lines\n",
    "split -l 100000 -a 4 --additional-suffix=.tsv $PROCESSED_BLASTN_PATH ${LABEL}.partition_\n",
    "ls -thor $BLAST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49f259a5-c46f-47cb-8d7b-854986e45b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T23:44:49.874460Z",
     "iopub.status.busy": "2025-03-01T23:44:49.874285Z",
     "iopub.status.idle": "2025-03-01T23:46:41.085376Z",
     "shell.execute_reply": "2025-03-01T23:46:41.084891Z",
     "shell.execute_reply.started": "2025-03-01T23:44:49.874440Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing exact alignment scores for partitioned files...\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.filter_existing_splits.work/blast_partitions/example_test_split.blastn.processed.partition_aaaa.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.filter_existing_splits.work/blast_partitions/example_test_split.blastn.processed.partition_aaab.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.filter_existing_splits.work/blast_partitions/example_test_split.blastn.processed.partition_aaac.tsv\n",
      "\n",
      "Concatenating partitioned files...\n",
      "BCL11A_1238\tHBE1_1082\t13.0\n",
      "BCL11A_1238\tpeak76790_Reversed\t14.0\n",
      "BCL11A_1238\tpeak82879_Reversed\t13.0\n",
      "BCL11A_1238\tENSG00000125386\t13.0\n",
      "BCL11A_1238\tpeak79031\t13.0\n",
      "BCL11A_1238\tpeak1501\t15.0\n",
      "BCL11A_1238\tpeak49119_Reversed\t14.0\n",
      "BCL11A_1238\tpeak21876_Reversed\t13.0\n",
      "BCL11A_1238\tGATA1_4792\t14.0\n",
      "BCL11A_1238\tpeak82428\t13.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "DATA_DIR=../data\n",
    "cd $DATA_DIR\n",
    "\n",
    "# note this is the complete FASTA file containing both train-test sequences\n",
    "FASTA_PATH=$PWD/example_full_dataset.fa\n",
    "WORK_DIR=$PWD/tutorial.filter_existing_splits.work\n",
    "BLAST_DIR=$WORK_DIR/blast_partitions\n",
    "\n",
    "cd ../src/external\n",
    "\n",
    "echo \"Computing exact alignment scores for partitioned files...\"\n",
    "for PARTITIONED_BLAST_PATH in $BLAST_DIR/*.partition_*.tsv\n",
    "do\n",
    "    echo $PARTITIONED_BLAST_PATH\n",
    "    bash compute_blast_candidate_SW_scores.sh $FASTA_PATH $PARTITIONED_BLAST_PATH\n",
    "done\n",
    "\n",
    "echo\n",
    "echo \"Concatenating partitioned files...\"\n",
    "cat $BLAST_DIR/*.pairwise_scores.tsv > $WORK_DIR/hashFrag_pure.blastn_candidates.sw_scores.tsv\n",
    "cat $WORK_DIR/hashFrag_pure.blastn_candidates.sw_scores.tsv | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "290ede5d-203d-4f50-ad6b-4ceab6d363f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T23:46:41.086303Z",
     "iopub.status.busy": "2025-03-01T23:46:41.086068Z",
     "iopub.status.idle": "2025-03-01T23:46:41.965609Z",
     "shell.execute_reply": "2025-03-01T23:46:41.965146Z",
     "shell.execute_reply.started": "2025-03-01T23:46:41.086281Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-02 08:46:41 - filter_candidates_module - INFO - Calling module...\n",
      "2025-03-02 08:46:41 - filter_candidates_module - INFO - Filtered results written to: ../data/tutorial.filter_existing_splits.work/hashFrag.similar_pairs.tsv\n",
      "2025-03-02 08:46:41 - filter_candidates_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.filter_existing_splits.work\n",
    "INPUT_PATH=$WORK_DIR/hashFrag_pure.blastn_candidates.sw_scores.tsv\n",
    "hashFrag filter_candidates_module -i $INPUT_PATH -t 60 -o $WORK_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e7ba0-6b31-4f9a-8a0f-91f34d9998a0",
   "metadata": {},
   "source": [
    "# Section 3: Use Case(s)\n",
    "\n",
    "## Filter test split sequences that exhibit homology with any sequences in the train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbb857a9-25de-4724-adcf-fcd635bc0b0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-01T23:46:41.966490Z",
     "iopub.status.busy": "2025-03-01T23:46:41.966274Z",
     "iopub.status.idle": "2025-03-01T23:46:42.983373Z",
     "shell.execute_reply": "2025-03-01T23:46:42.982904Z",
     "shell.execute_reply.started": "2025-03-01T23:46:41.966470Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-02 08:46:42 - filter_test_split_module - INFO - Calling module...\n",
      "2025-03-02 08:46:42 - filter_test_split_module - INFO - 201 sequences filtered from test split.\n",
      "2025-03-02 08:46:42 - filter_test_split_module - INFO - Filtered results written to: ../data/example_test_split.filtered.fa\n",
      "2025-03-02 08:46:42 - filter_test_split_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "TRAIN_FASTA_PATH=../data/example_train_split.fa\n",
    "TEST_FASTA_PATH=../data/example_test_split.fa\n",
    "WORK_DIR=../data/tutorial.filter_existing_splits.work\n",
    "HITS_PATH=$WORK_DIR/hashFrag.similar_pairs.tsv\n",
    "\n",
    "hashFrag filter_test_split_module \\\n",
    "--train-fasta-path $TRAIN_FASTA_PATH \\\n",
    "--test-fasta-path $TEST_FASTA_PATH \\\n",
    "--hits-path $HITS_PATH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
