{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cad5423-820a-4c05-924f-a9c046372489",
   "metadata": {},
   "source": [
    "# `help` commands for general usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c5272d-1889-41ca-b3fb-60614d5f83c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T19:50:14.373746Z",
     "iopub.status.busy": "2025-01-10T19:50:14.373519Z",
     "iopub.status.idle": "2025-01-10T19:50:14.683150Z",
     "shell.execute_reply": "2025-01-10T19:50:14.682610Z",
     "shell.execute_reply.started": "2025-01-10T19:50:14.373725Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: hashFrag [-h]\n",
      "                {blastn_module,filter_candidates_module,filter_test_split_module,stratify_test_split_module,identify_homologous_groups_module,create_orthogonal_splits_module,filter_existing_splits,stratify_test_split,create_orthogonal_splits}\n",
      "                ...\n",
      "\n",
      "hashFrag is a tool developed to mitigate the impacts of homology-based data leakage in sequence-to-expression models. By identifying homology (based on\n",
      "pairwise alignment scores) in a sequence dataset, this tool can be used to filter homologous sequences spanning existing train-test splits (e.g.,\n",
      "chromosomal splits), stratify a test split according to different levels of homology, or create homology-aware train-test splits.\n",
      "\n",
      "positional arguments:\n",
      "  {blastn_module,filter_candidates_module,filter_test_split_module,stratify_test_split_module,identify_homologous_groups_module,create_orthogonal_splits_module,filter_existing_splits,stratify_test_split,create_orthogonal_splits}\n",
      "    blastn_module       A wrapper script calling BLASTn to identify candidate pairs of sequences sharing regions with high similarity.\n",
      "    filter_candidates_module\n",
      "                        Filter candidate pairs based on a specified alignment score threshold (false-positive removal).\n",
      "    filter_test_split_module\n",
      "                        Filter test sequences that exhibit homology with any train sequences.\n",
      "    stratify_test_split_module\n",
      "                        Stratify the test split into subsplits based on their maximum alignment score to the sequences in the train split.\n",
      "    identify_homologous_groups_module\n",
      "                        Identify all distinct groups of homologous sequences.\n",
      "    create_orthogonal_splits_module\n",
      "                        Create homology-aware test-train splits.\n",
      "    filter_existing_splits\n",
      "                        Execute the full workflow of commands to filter homology spanning the input test splits.\n",
      "    stratify_test_split\n",
      "                        Execute the full workflow of commands to stratify the test split based on their maximum pairwise alignment score to the train\n",
      "                        split sequences.\n",
      "    create_orthogonal_splits\n",
      "                        Execute the full workflow of commands to create homology-aware train-test splits.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "hashFrag -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb6a5f7-4f8c-4e40-a165-92b2e7c9db0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T19:50:25.095865Z",
     "iopub.status.busy": "2025-01-10T19:50:25.095611Z",
     "iopub.status.idle": "2025-01-10T19:50:25.386295Z",
     "shell.execute_reply": "2025-01-10T19:50:25.385792Z",
     "shell.execute_reply.started": "2025-01-10T19:50:25.095840Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: hashFrag create_orthogonal_splits [-h] [-f FASTA_PATH] [-w WORD_SIZE] [-g GAPOPEN] [-x GAPEXTEND] [-p PENALTY] [-r REWARD] [-m MAX_TARGET_SEQS]\n",
      "                                         [-e E_VALUE] [-d DUST] [-b BLASTDB_ARGS] [--blastdb_label BLASTDB_LABEL] [-B BLASTN_ARGS] [-T THREADS] -t\n",
      "                                         THRESHOLD [--p_train P_TRAIN] [--p_test P_TEST] [-n N_SPLITS] [-s SEED] [--force] [-o OUTPUT_DIR]\n",
      "\n",
      "Execute the full workflow of commands to create homology-aware train-test splits. This involves identifying identifying pairs of sequences sharing\n",
      "similarities with BLAST, filtering candidates based on a specified threshold, identifying all the different subgroups of sequences exhibiting a distinct\n",
      "case of homology, and creating train-test splits with no leakage.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -f FASTA_PATH, --fasta_path FASTA_PATH\n",
      "                        Input FASTA file containing all sequences in the dataset. All sequences will comprise the BLAST database and each sequence will\n",
      "                        subsequently be queried against it.\n",
      "  -w WORD_SIZE, --word_size WORD_SIZE\n",
      "                        Length of exact matching subsequences of initial match.\n",
      "  -g GAPOPEN, --gapopen GAPOPEN\n",
      "                        Penalty for opening gap in the alignment.\n",
      "  -x GAPEXTEND, --gapextend GAPEXTEND\n",
      "                        Penalty for extending an existing gap in the alignment.\n",
      "  -p PENALTY, --penalty PENALTY\n",
      "                        Nucleotide mismatch in penalty the alignment.\n",
      "  -r REWARD, --reward REWARD\n",
      "                        Nucleotide match reward in the alignment.\n",
      "  -m MAX_TARGET_SEQS, --max_target_seqs MAX_TARGET_SEQS\n",
      "                        The maximum number of target sequences that can be returned per query sequence.\n",
      "  -e E_VALUE, --e_value E_VALUE\n",
      "                        The likelihood threshold required to report sequences as a match.\n",
      "  -d DUST, --dust DUST  Filter low-complexity (e.g., repetitive) regions.\n",
      "  -b BLASTDB_ARGS, --blastdb_args BLASTDB_ARGS\n",
      "                        Pass additional arguments for makeblastdb call.\n",
      "  --blastdb_label BLASTDB_LABEL\n",
      "                        A label for the BLAST database.\n",
      "  -B BLASTN_ARGS, --blastn_args BLASTN_ARGS\n",
      "                        Pass additional arguments for blastn call.\n",
      "  -T THREADS, --threads THREADS\n",
      "                        The number of CPUs for database search.\n",
      "  -t THRESHOLD, --threshold THRESHOLD\n",
      "                        Alignment score threshold to discern a pair of sequences as homologous or a false-positive candidate.\n",
      "  --p_train P_TRAIN     The proportion of sequences to send to the train data split.\n",
      "  --p_test P_TEST       The proportion of sequences to send to the test data split.\n",
      "  -n N_SPLITS, --n_splits N_SPLITS\n",
      "                        Number of split replicates to create.\n",
      "  -s SEED, --seed SEED  Random seed to use for the creation of homology-aware data splits.\n",
      "  --force               Force overwrite BLAST module procedure (default: False)\n",
      "  -o OUTPUT_DIR, --output_dir OUTPUT_DIR\n",
      "                        The directory to write the created train-test splits.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "hashFrag create_orthogonal_splits -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381d6c3-0050-401e-87b1-c5b2eb76cc78",
   "metadata": {},
   "source": [
    "# Section 0: Introduction\n",
    "\n",
    "> This notebook refers to the case when users have a nucleotide sequence dataset and are interested in creating homology-aware train-test data splits for sequence-to-expression models.\n",
    "\n",
    "The basic workflow is provided with respect a subsampled MPRA dataset (K562): a 10,000-sequence FASTA file (provided in the `data` directory).\n",
    "\n",
    "This notebook serves a walkthrough of calling the individual modules comprising the `hashFrag create_orthogonal_splits` command. The basic usage command only supports \"lightning\" mode, and can be called as follows:\n",
    "```\n",
    "FASTA_PATH=../data/example_full_dataset.fa.gz\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "\n",
    "WORD_SIZE=7\n",
    "MAX_TARGET_SEQS=10000 # size of train dataset\n",
    "E_VALUE=100\n",
    "THRESHOLD=60\n",
    "N_SPLITS=10\n",
    "\n",
    "hashFrag create_orthogonal_splits \\\n",
    "--fasta_path $FASTA_PATH \\\n",
    "--word_size $WORD_SIZE \\\n",
    "--max_target_seqs $MAX_TARGET_SEQS \\\n",
    "--e_value $E_VALUE \\\n",
    "--threshold $THRESHOLD \\\n",
    "--n_splits $N_SPLITS \\\n",
    "--force \\\n",
    "--output_dir $WORK_DIR\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0deed-41d6-4976-b81c-d2a40d809ba9",
   "metadata": {},
   "source": [
    "# Section 1 - Identifying candidate similar sequences\n",
    "\n",
    "The process of identifying candidate pairs of similar sequences involves first creating a BLAST database of the dataset, and then querying each sequence against the database. The BLASTn algorithm returns pairwise matches that represent potential cases of homology. \n",
    "\n",
    "Successful identification of cases of homology is paramount to effectively mitigate homology-based data leakage. As such, we configure the BLASTn parameters such that recall is maximized, even if it comes at the expense of increased false-positives. Here we consider the following parameters of BLASTn:\n",
    "\n",
    "* word_size: smaller word sizes results in more exact word matches found between the query and sequences in the database, leading to more alignment score calculations being initialized.\n",
    "* max_target_seqs: set to the size of the database to remove any constraints and allow for all possible candidate sequences to be returned for a given query.\n",
    "* evalue: the e-value statistic is a measure of how likely you observe the alignment by chance (lower value corresponds to less likely to observe). By increasing the e-value threshold, less stringent matches that could be due to chance are returned.\n",
    "* dust: by setting dust off, low-complexity (e.g., repetitive sequences) are no longer masked/filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fc29f5e-cba3-4433-b10b-2f7a3c871292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:03:55.065804Z",
     "iopub.status.busy": "2025-01-10T20:03:55.065411Z",
     "iopub.status.idle": "2025-01-10T20:03:59.187849Z",
     "shell.execute_reply": "2025-01-10T20:03:59.187099Z",
     "shell.execute_reply.started": "2025-01-10T20:03:55.065780Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11 05:03:59 - blastn_module - INFO - Calling module...\n",
      "2025-01-11 05:03:59 - blastn_module - INFO - One FASTA files detected. Computing pairwise BLAST comparisons for all sequence-pairs...\n",
      "2025-01-11 05:03:59 - blastn_module - INFO - Existing BLAST database found. Path: ../data/tutorial.create_orthogonal_splits.work/hashFrag.blastdb\n",
      "2025-01-11 05:03:59 - blastn_module - INFO - Skipping `makeblastdb` call...\n",
      "2025-01-11 05:03:59 - blastn_module - INFO - Existing BLAST results file found. Path: ../data/tutorial.create_orthogonal_splits.work/hashFrag.blastn.out\n",
      "2025-01-11 05:03:59 - blastn_module - INFO - Skipping `blastn` call.\n",
      "2025-01-11 05:03:59 - blastn_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FASTA_PATH=../data/example_full_dataset.fa.gz\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "\n",
    "WORD_SIZE=7\n",
    "MAX_TARGET_SEQS=10000 # size of dataset\n",
    "E_VALUE=100\n",
    "\n",
    "hashFrag blastn_module \\\n",
    "-f $FASTA_PATH \\\n",
    "-m $MAX_TARGET_SEQS \\\n",
    "-w $WORD_SIZE \\\n",
    "-e $E_VALUE \\\n",
    "--blastdb_label \"hashFrag\" \\\n",
    "-o $WORK_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d63c8e-42ca-451d-acc0-0f4f336c5f12",
   "metadata": {},
   "source": [
    "# Section 2: Filter false-positives based on a defined threshold\n",
    "\n",
    "The next step involves filtering candidate pairings with alignment scores lower than the specified threshold. There are two different modes of hashFrag depending on what alignment score is selected.\n",
    "\n",
    "* `hashFrag-lightning` is the faster version where the alignment score computed from the BLAST output file. BLASTn is a heuristic method and the alignment scores were found to highly correlate with the optimal alignment scores; however, its underestimation of homology in some cases can lead to slightly worse recall. \n",
    "* `hashFrag-pure` is the slower but more comprehensive method that is based on the optimal, Smith-Waterman local alignment scores between pairs of sequences. The calculation of optimal alignment scores incurs an additional cost to filtering.\n",
    "\n",
    "An alignment score threshold of 60 was determined to be appropriate based on an analysis looking at alignment scores between dinucleotide shuffled (i.e., random) sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e904fb3a-8107-4e46-a4d2-f64c55f2d703",
   "metadata": {},
   "source": [
    "## Section 2.1: Lightning mode (Default behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b48ccad1-aa5f-4546-96c1-eb1d2f92f8e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:04:05.811386Z",
     "iopub.status.busy": "2025-01-10T20:04:05.811012Z",
     "iopub.status.idle": "2025-01-10T20:04:12.251825Z",
     "shell.execute_reply": "2025-01-10T20:04:12.251132Z",
     "shell.execute_reply.started": "2025-01-10T20:04:05.811361Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11 05:04:09 - numexpr.utils - INFO - Note: detected 128 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2025-01-11 05:04:09 - numexpr.utils - INFO - Note: NumExpr detected 128 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "2025-01-11 05:04:09 - numexpr.utils - INFO - NumExpr defaulting to 16 threads.\n",
      "2025-01-11 05:04:11 - filter_candidates_module - INFO - Calling module...\n",
      "2025-01-11 05:04:11 - filter_candidates_module - INFO - Filtering based on corrected BLAST alignment scores (lightning mode).\n",
      "2025-01-11 05:04:12 - filter_candidates_module - INFO - Filtered results written to: ../data/tutorial.create_orthogonal_splits.work/hashFrag_lightning.similar_pairs.tsv.gz\n",
      "2025-01-11 05:04:12 - filter_candidates_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "INPUT_PATH=$WORK_DIR/hashFrag.blastn.out\n",
    "MODE=lightning\n",
    "THRESHOLD=60\n",
    "\n",
    "hashFrag filter_candidates_module -m $MODE -i $INPUT_PATH -t $THRESHOLD -o $WORK_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de3a6b-cfb9-4dac-a41b-3e67e972f9fa",
   "metadata": {},
   "source": [
    "## Section 2.2: Pure mode (optional)\n",
    "\n",
    "To limit memory usage, we'll start by partitioning the blast output file based on size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed5859ff-f987-4657-9893-5eda20be19a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:11:37.270177Z",
     "iopub.status.busy": "2025-01-10T20:11:37.269928Z",
     "iopub.status.idle": "2025-01-10T20:11:37.463419Z",
     "shell.execute_reply": "2025-01-10T20:11:37.462950Z",
     "shell.execute_reply.started": "2025-01-10T20:11:37.270151Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.5K\n",
      "-rw-r----- 1 brett 584K Jan 11 05:11 hashFrag.blastn.partition_aaai.tsv\n",
      "-rw-r----- 1 brett 7.3M Jan 11 05:11 hashFrag.blastn.partition_aaah.tsv\n",
      "-rw-r----- 1 brett 7.3M Jan 11 05:11 hashFrag.blastn.partition_aaag.tsv\n",
      "-rw-r----- 1 brett 7.3M Jan 11 05:11 hashFrag.blastn.partition_aaaf.tsv\n",
      "-rw-r----- 1 brett 7.3M Jan 11 05:11 hashFrag.blastn.partition_aaae.tsv\n",
      "-rw-r----- 1 brett 7.3M Jan 11 05:11 hashFrag.blastn.partition_aaad.tsv\n",
      "-rw-r----- 1 brett 7.3M Jan 11 05:11 hashFrag.blastn.partition_aaac.tsv\n",
      "-rw-r----- 1 brett 7.3M Jan 11 05:11 hashFrag.blastn.partition_aaab.tsv\n",
      "-rw-r----- 1 brett 7.3M Jan 11 05:11 hashFrag.blastn.partition_aaaa.tsv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "\n",
    "cd $WORK_DIR\n",
    "BLAST_PATH=$PWD/hashFrag.blastn.out\n",
    "BLAST_DIR=$PWD/blast_partitions\n",
    "LABEL=$( basename -s \".out\" $BLAST_PATH )\n",
    "\n",
    "mkdir -p $BLAST_DIR\n",
    "cd $BLAST_DIR\n",
    "\n",
    "SPLIT_SIZE=100000\n",
    "\n",
    "split -l $SPLIT_SIZE -a 4 --additional-suffix=.tsv $BLAST_PATH ${LABEL}.partition_\n",
    "\n",
    "ls -thor $BLAST_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a5b0f-188c-46eb-88f5-992fe32a712a",
   "metadata": {},
   "source": [
    "This bash script execution will call a custom python script that computes pairwise Smith-Waterman local alignment scores for the candidate pairs of sequences identified by the BLASTn algorithm. Note that this could feasibly be replaced with any scoring metric of interest.\n",
    "\n",
    "The expected format output files consists of a tab-delimited file with 3 columns: the query sequence iD, the target seqeuence ID, and their alignment score:\n",
    "```\n",
    "seq1    seq2    100\n",
    "seq3    seq4    30\n",
    "seq5    seq6    65\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26e67396-e139-4544-868b-7b1eeea37b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:14:00.962400Z",
     "iopub.status.busy": "2025-01-10T20:14:00.962184Z",
     "iopub.status.idle": "2025-01-10T20:20:46.466299Z",
     "shell.execute_reply": "2025-01-10T20:20:46.465612Z",
     "shell.execute_reply.started": "2025-01-10T20:14:00.962381Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.partition_aaaa.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.partition_aaab.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.partition_aaac.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.partition_aaad.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.partition_aaae.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.partition_aaaf.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.partition_aaag.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.partition_aaah.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.partition_aaai.tsv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "DATA_DIR=../data\n",
    "cd $DATA_DIR\n",
    "\n",
    "FASTA_PATH=$PWD/example_full_dataset.fa.gz\n",
    "WORK_DIR=$PWD/tutorial.create_orthogonal_splits.work\n",
    "BLAST_DIR=$WORK_DIR/blast_partitions\n",
    "\n",
    "cd ../src/external\n",
    "\n",
    "for PARTITIONED_BLAST_PATH in $BLAST_DIR/*.blastn.partition_*.tsv\n",
    "do\n",
    "    echo $PARTITIONED_BLAST_PATH\n",
    "    bash compute_blast_candidate_SW_scores.sh $FASTA_PATH $PARTITIONED_BLAST_PATH\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bde38a-6f74-46f4-960c-9d2ab6aea8fb",
   "metadata": {},
   "source": [
    "The SW scores for candidate pairs of sequences can subsequently be concatenated into a single `.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b019aebd-9fa0-43ca-b80b-d1150deabe90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:22:03.484893Z",
     "iopub.status.busy": "2025-01-10T20:22:03.484519Z",
     "iopub.status.idle": "2025-01-10T20:22:04.398678Z",
     "shell.execute_reply": "2025-01-10T20:22:04.398070Z",
     "shell.execute_reply.started": "2025-01-10T20:22:03.484873Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCL11A_1542\tGATA1_9703\t15.0\n",
      "BCL11A_1542\tpeak63709_Reversed\t15.0\n",
      "BCL11A_1542\tBCL11A_1542\t200.0\n",
      "BCL11A_1542\tpeak64077_Reversed\t17.0\n",
      "BCL11A_1542\tpeak9935\t14.0\n",
      "BCL11A_1542\tpeak83991_Reversed\t15.0\n",
      "BCL11A_1542\tpeak58146\t16.0\n",
      "BCL11A_1542\tRBM38_1662\t16.0\n",
      "BCL11A_1542\tpeak31193\t14.0\n",
      "BCL11A_1542\tHBA2_591_Reversed\t16.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "BLAST_DIR=$WORK_DIR/blast_partitions\n",
    "\n",
    "zcat $BLAST_DIR/*.pairwise_scores.tsv.gz | gzip > $WORK_DIR/hashFrag_pure.blastn_candidates.sw_scores.tsv.gz\n",
    "\n",
    "zcat $WORK_DIR/hashFrag_pure.blastn_candidates.sw_scores.tsv.gz | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b623b03-e9b5-4bf3-ac49-89db8b95d63e",
   "metadata": {},
   "source": [
    "Rather than using the heuristic alignment scores provided by the BLASTn algorithm, we can filter false-positives based on SW alignment scores. Make sure to set the mode to `pure`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c8e40c2-0972-4413-9201-37fbf60e124b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:22:12.629227Z",
     "iopub.status.busy": "2025-01-10T20:22:12.629009Z",
     "iopub.status.idle": "2025-01-10T20:22:15.811517Z",
     "shell.execute_reply": "2025-01-10T20:22:15.810913Z",
     "shell.execute_reply.started": "2025-01-10T20:22:12.629207Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11 05:22:14 - numexpr.utils - INFO - Note: detected 128 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2025-01-11 05:22:14 - numexpr.utils - INFO - Note: NumExpr detected 128 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "2025-01-11 05:22:14 - numexpr.utils - INFO - NumExpr defaulting to 16 threads.\n",
      "2025-01-11 05:22:15 - filter_candidates_module - INFO - Calling module...\n",
      "2025-01-11 05:22:15 - filter_candidates_module - INFO - Filtering based on precomputed alignment scores (pure mode).\n",
      "2025-01-11 05:22:15 - filter_candidates_module - INFO - Filtered results written to: ../data/tutorial.create_orthogonal_splits.work/hashFrag_pure.similar_pairs.tsv.gz\n",
      "2025-01-11 05:22:15 - filter_candidates_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "INPUT_PATH=$WORK_DIR/hashFrag_pure.blastn_candidates.sw_scores.tsv.gz\n",
    "MODE=pure\n",
    "THRESHOLD=60\n",
    "\n",
    "hashFrag filter_candidates_module -m $MODE -i $INPUT_PATH -t $THRESHOLD -o $WORK_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c75343-485f-441c-9576-e4c61b82ccb0",
   "metadata": {},
   "source": [
    "# Section 3: Determine groups of homology\n",
    "\n",
    "There are often distinct groups of sequences exhibiting different cases of homology throughout the dataset. To determine such groups, we represent the \"hits\" (i.e., pairs of sequences with an alignment score greater than the threshold) as a sparse adjacency matrix. A graph can then be constructed, where nodes correspond to sequences and edges denote shared homology between the two sequences. The process of identifying groups of homology can readily be solved by identifying disconnected subgraphs. \n",
    "\n",
    "An efficient implementation for this graph-based task is provided in the `igraph` Python library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5aff80-d28b-4382-9701-5f2526f1079e",
   "metadata": {},
   "source": [
    "## Section 3.1: `lightning`-filtered homologous pairs (Default behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1990b87e-d476-44fc-9db6-e2c17b38a1a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:22:26.483245Z",
     "iopub.status.busy": "2025-01-10T20:22:26.482999Z",
     "iopub.status.idle": "2025-01-10T20:22:30.562278Z",
     "shell.execute_reply": "2025-01-10T20:22:30.561628Z",
     "shell.execute_reply.started": "2025-01-10T20:22:26.483222Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11 05:22:29 - numexpr.utils - INFO - Note: detected 128 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2025-01-11 05:22:29 - numexpr.utils - INFO - Note: NumExpr detected 128 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "2025-01-11 05:22:29 - numexpr.utils - INFO - NumExpr defaulting to 16 threads.\n",
      "2025-01-11 05:22:30 - identify_homologous_groups_module - INFO - Calling module...\n",
      "2025-01-11 05:22:30 - identify_homologous_groups_module - INFO - 1114 sequences exhibiting homology.\n",
      "2025-01-11 05:22:30 - identify_homologous_groups_module - INFO - 90 distinct groups.\n",
      "2025-01-11 05:22:30 - identify_homologous_groups_module - INFO - Homologous groups written to: ../data/tutorial.create_orthogonal_splits.work/homologous_groups.lightning.csv\n",
      "2025-01-11 05:22:30 - identify_homologous_groups_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "HITS_PATH=$WORK_DIR/hashFrag_lightning.similar_pairs.tsv.gz\n",
    "OUTPUT_PATH=$WORK_DIR/homologous_groups.lightning.csv\n",
    "\n",
    "hashFrag identify_homologous_groups_module -i $HITS_PATH -o $OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c716c81f-6b1e-41f9-8e6f-0ac74a651f55",
   "metadata": {},
   "source": [
    "## Section 3.2: `pure`-filtered homologous pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6f54fd6-7039-4304-95eb-2bf5974bef81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:22:30.563527Z",
     "iopub.status.busy": "2025-01-10T20:22:30.563352Z",
     "iopub.status.idle": "2025-01-10T20:22:31.808506Z",
     "shell.execute_reply": "2025-01-10T20:22:31.807867Z",
     "shell.execute_reply.started": "2025-01-10T20:22:30.563506Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11 05:22:31 - numexpr.utils - INFO - Note: detected 128 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "2025-01-11 05:22:31 - numexpr.utils - INFO - Note: NumExpr detected 128 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 16.\n",
      "2025-01-11 05:22:31 - numexpr.utils - INFO - NumExpr defaulting to 16 threads.\n",
      "2025-01-11 05:22:31 - identify_homologous_groups_module - INFO - Calling module...\n",
      "2025-01-11 05:22:31 - identify_homologous_groups_module - INFO - 1138 sequences exhibiting homology.\n",
      "2025-01-11 05:22:31 - identify_homologous_groups_module - INFO - 92 distinct groups.\n",
      "2025-01-11 05:22:31 - identify_homologous_groups_module - INFO - Homologous groups written to: ../data/tutorial.create_orthogonal_splits.work/homologous_groups.pure.csv\n",
      "2025-01-11 05:22:31 - identify_homologous_groups_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "HITS_PATH=$WORK_DIR/hashFrag_pure.similar_pairs.tsv.gz\n",
    "OUTPUT_PATH=$WORK_DIR/homologous_groups.pure.csv\n",
    "\n",
    "hashFrag identify_homologous_groups_module -i $HITS_PATH -o $OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5565f51-e041-490a-a639-519dff059526",
   "metadata": {},
   "source": [
    "# Section 4: Use case(s)\n",
    "\n",
    "Upon identifying groups of sequences exhibiting high similarity (i.e., homology), we can create train-test data splits using a graph-based method. Specifically, by representing sequences as nodes and using edges to denote whether sequences were found to be homologous (yes or no), identifying homologous groups of sequences can be reduced to the task of identifying all disconnected subgraphs in the population. \n",
    "\n",
    "## Creating homology-aware data splits\n",
    "\n",
    "Below we show how splits can be created based on the homologous groups identified from either the `hashFrag-lightning` or `hashFrag-pure` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebbc568a-ae85-4df6-a990-0b52f05e6866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:22:48.967278Z",
     "iopub.status.busy": "2025-01-10T20:22:48.966998Z",
     "iopub.status.idle": "2025-01-10T20:22:52.169720Z",
     "shell.execute_reply": "2025-01-10T20:22:52.169099Z",
     "shell.execute_reply.started": "2025-01-10T20:22:48.967250Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11 05:22:49 - create_orthogonal_splits_module - INFO - Calling module...\n",
      "2025-01-11 05:22:49 - create_orthogonal_splits_module - INFO - Creating 10 orthogonal splits in directory: ../data/tutorial.create_orthogonal_splits.work\n",
      "2025-01-11 05:22:52 - create_orthogonal_splits_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FASTA_PATH=../data/example_full_dataset.fa.gz\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "HOMOLOGY_PATH=$WORK_DIR/homologous_groups.lightning.csv # lightning mode (Default behavior)\n",
    "OUT_DIR=$WORK_DIR\n",
    "\n",
    "hashFrag create_orthogonal_splits_module -f $FASTA_PATH -i $HOMOLOGY_PATH -n 10 -o $OUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8b8f59f-0c8b-4118-a4b9-1e4962996887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T20:22:52.170933Z",
     "iopub.status.busy": "2025-01-10T20:22:52.170758Z",
     "iopub.status.idle": "2025-01-10T20:22:55.229519Z",
     "shell.execute_reply": "2025-01-10T20:22:55.228743Z",
     "shell.execute_reply.started": "2025-01-10T20:22:52.170912Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-11 05:22:52 - create_orthogonal_splits_module - INFO - Calling module...\n",
      "2025-01-11 05:22:52 - create_orthogonal_splits_module - INFO - Creating 10 orthogonal splits in directory: ../data/tutorial.create_orthogonal_splits.work\n",
      "2025-01-11 05:22:55 - create_orthogonal_splits_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FASTA_PATH=../data/example_full_dataset.fa.gz\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "HOMOLOGY_PATH=$WORK_DIR/homologous_groups.pure.csv # pure mode\n",
    "OUT_DIR=$WORK_DIR\n",
    "\n",
    "hashFrag create_orthogonal_splits_module -f $FASTA_PATH -i $HOMOLOGY_PATH -n 10 -o $OUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d110dbe5-446d-437e-b5bd-d1b8210297e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
