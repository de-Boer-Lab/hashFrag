{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c03f6b8-28ad-4f0b-961e-22b20cc293a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:20:34.510058Z",
     "iopub.status.busy": "2025-07-08T05:20:34.509643Z",
     "iopub.status.idle": "2025-07-08T05:20:34.512323Z",
     "shell.execute_reply": "2025-07-08T05:20:34.512056Z",
     "shell.execute_reply.started": "2025-07-08T05:20:34.510040Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '1' # just to prevent warning NUMEXPR messages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad5423-820a-4c05-924f-a9c046372489",
   "metadata": {},
   "source": [
    "# `help` commands for general usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c5272d-1889-41ca-b3fb-60614d5f83c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:34:02.974877Z",
     "iopub.status.busy": "2025-07-08T05:34:02.974547Z",
     "iopub.status.idle": "2025-07-08T05:34:03.626345Z",
     "shell.execute_reply": "2025-07-08T05:34:03.625609Z",
     "shell.execute_reply.started": "2025-07-08T05:34:02.974852Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: hashFrag [-h]\n",
      "                {blastn_module,blastn_array_module,process_blast_results_module,filter_candidates_module,filter_test_split_module,stratify_test_split_module,identify_homologous_groups_module,create_orthogonal_splits_module,filter_existing_splits,stratify_test_split,create_orthogonal_splits}\n",
      "                ...\n",
      "\n",
      "hashFrag is a tool developed to mitigate the impacts of homology-based data\n",
      "leakage in sequence-to-expression models. By identifying homology (based on\n",
      "pairwise alignment scores) in a sequence dataset, this tool can be used to\n",
      "filter homologous sequences spanning existing train-test splits (e.g.,\n",
      "chromosomal splits), stratify a test split according to different levels of\n",
      "homology, or create homology-aware train-test splits.\n",
      "\n",
      "positional arguments:\n",
      "  {blastn_module,blastn_array_module,process_blast_results_module,filter_candidates_module,filter_test_split_module,stratify_test_split_module,identify_homologous_groups_module,create_orthogonal_splits_module,filter_existing_splits,stratify_test_split,create_orthogonal_splits}\n",
      "    blastn_module       A wrapper script calling BLASTn to identify candidate\n",
      "                        pairs of sequences sharing regions with high\n",
      "                        similarity.\n",
      "    blastn_array_module\n",
      "                        A wrapper script to set up an array job calling BLASTn\n",
      "                        to identify candidate pairs of sequences sharing\n",
      "                        regions with high similarity.\n",
      "    process_blast_results_module\n",
      "                        A wrapper script calling BLASTn to identify candidate\n",
      "                        pairs of sequences sharing regions with high\n",
      "                        similarity.\n",
      "    filter_candidates_module\n",
      "                        Filter candidate pairs based on a specified alignment\n",
      "                        score threshold (false-positive removal).\n",
      "    filter_test_split_module\n",
      "                        Filter test sequences that exhibit homology with any\n",
      "                        train sequences.\n",
      "    stratify_test_split_module\n",
      "                        Stratify the test split into subsplits based on their\n",
      "                        maximum alignment score to the sequences in the train\n",
      "                        split.\n",
      "    identify_homologous_groups_module\n",
      "                        Identify all distinct groups of homologous sequences.\n",
      "    create_orthogonal_splits_module\n",
      "                        Create homology-aware test-train splits.\n",
      "    filter_existing_splits\n",
      "                        Execute the full workflow of commands to filter\n",
      "                        homology spanning the input test splits.\n",
      "    stratify_test_split\n",
      "                        Execute the full workflow of commands to stratify the\n",
      "                        test split based on their maximum pairwise alignment\n",
      "                        score to the train split sequences.\n",
      "    create_orthogonal_splits\n",
      "                        Execute the full workflow of commands to create\n",
      "                        homology-aware train-test splits.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "hashFrag -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb6a5f7-4f8c-4e40-a165-92b2e7c9db0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:34:06.920101Z",
     "iopub.status.busy": "2025-07-08T05:34:06.919777Z",
     "iopub.status.idle": "2025-07-08T05:34:07.188799Z",
     "shell.execute_reply": "2025-07-08T05:34:07.188072Z",
     "shell.execute_reply.started": "2025-07-08T05:34:06.920084Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: hashFrag create_orthogonal_splits [-h] [-f FASTA_PATH] [-w WORD_SIZE]\n",
      "                                         [-g GAPOPEN] [-x GAPEXTEND]\n",
      "                                         [-p PENALTY] [-r REWARD]\n",
      "                                         [-m MAX_TARGET_SEQS]\n",
      "                                         [--exec-makeblastdb-only]\n",
      "                                         [--skip-revcomp]\n",
      "                                         [--xdrop-ungap XDROP_UNGAP]\n",
      "                                         [--xdrop-gap XDROP_GAP]\n",
      "                                         [--xdrop-gap_final XDROP_GAP_FINAL]\n",
      "                                         [-e EVALUE] [-d DUST]\n",
      "                                         [-b BLASTDB_ARGS]\n",
      "                                         [--blastdb-label BLASTDB_LABEL]\n",
      "                                         [-B BLASTN_ARGS] [-T THREADS] -t\n",
      "                                         THRESHOLD [--p-train P_TRAIN]\n",
      "                                         [--p-test P_TEST] [-n N_SPLITS]\n",
      "                                         [-s SEED] [--force] [-o OUTPUT_DIR]\n",
      "\n",
      "Execute the full workflow of commands to create homology-aware train-test\n",
      "splits. This involves identifying identifying pairs of sequences sharing\n",
      "similarities with BLAST, filtering candidates based on a specified threshold,\n",
      "identifying all the different subgroups of sequences exhibiting a distinct\n",
      "case of homology, and creating train-test splits with no leakage.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -f FASTA_PATH, --fasta-path FASTA_PATH\n",
      "                        Input FASTA file containing all sequences in the\n",
      "                        dataset. All sequences will comprise the BLAST\n",
      "                        database and each sequence will subsequently be\n",
      "                        queried against it (supports unzipped or gzipped file\n",
      "                        formats).\n",
      "  -w WORD_SIZE, --word_size WORD_SIZE\n",
      "                        Length of exact matching subsequences of initial match\n",
      "                        (Default: 11).\n",
      "  -g GAPOPEN, --gapopen GAPOPEN\n",
      "                        Penalty (positive value) for opening gap in the\n",
      "                        alignment (Default: 2).\n",
      "  -x GAPEXTEND, --gapextend GAPEXTEND\n",
      "                        Penalty (positive value) for extending an existing gap\n",
      "                        in the alignment (Default: 1).\n",
      "  -p PENALTY, --penalty PENALTY\n",
      "                        Nucleotide mismatch in penalty (negative value) the\n",
      "                        alignment (Default: -1).\n",
      "  -r REWARD, --reward REWARD\n",
      "                        Nucleotide match reward in the alignment (Default: 1).\n",
      "  -m MAX_TARGET_SEQS, --max-target-seqs MAX_TARGET_SEQS\n",
      "                        The maximum number of target sequences that can be\n",
      "                        returned per query sequence (Default: 500).\n",
      "  --exec-makeblastdb-only\n",
      "                        Only run the makeblastdb command (default: False, set\n",
      "                        to True when specified).\n",
      "  --skip-revcomp        Skip generating reverse complement of sequences\n",
      "                        comprising the BLAST database (Default: False,\n",
      "                        generated if not skipped).\n",
      "  --xdrop-ungap XDROP_UNGAP\n",
      "                        X-drop threshold for ungapped alignment extension\n",
      "                        (Permissible values: real numbers; Default: 20).\n",
      "  --xdrop-gap XDROP_GAP\n",
      "                        X-drop threshold for gapped alignment extension\n",
      "                        (Permissible values: real numbers; Default: 30).\n",
      "  --xdrop-gap_final XDROP_GAP_FINAL\n",
      "                        X-drop threshold for final alignment extension\n",
      "                        (Permissible values: real numbers; Default: 100).\n",
      "  -e EVALUE, --evalue EVALUE\n",
      "                        The likelihood threshold required to report sequences\n",
      "                        as a match (Default: 10).\n",
      "  -d DUST, --dust DUST  Filter low-complexity (e.g., repetitive) regions\n",
      "                        (Default: 'no').\n",
      "  -b BLASTDB_ARGS, --blastdb-args BLASTDB_ARGS\n",
      "                        Pass additional arguments for makeblastdb call.\n",
      "  --blastdb-label BLASTDB_LABEL\n",
      "                        A label for the BLAST database.\n",
      "  -B BLASTN_ARGS, --blastn-args BLASTN_ARGS\n",
      "                        Pass additional arguments for blastn call.\n",
      "  -T THREADS, --threads THREADS\n",
      "                        The number of CPUs for database search (Default: 1).\n",
      "  -t THRESHOLD, --threshold THRESHOLD\n",
      "                        Alignment score threshold to discern a pair of\n",
      "                        sequences as homologous or a false-positive candidate.\n",
      "  --p-train P_TRAIN     The proportion of sequences to send to the train data\n",
      "                        split (Default: 0.8).\n",
      "  --p-test P_TEST       The proportion of sequences to send to the test data\n",
      "                        split (Default: 0.2).\n",
      "  -n N_SPLITS, --n-splits N_SPLITS\n",
      "                        Number of split replicates to create (Default: 1).\n",
      "  -s SEED, --seed SEED  Random seed to use for the creation of homology-aware\n",
      "                        data splits (Default 21).\n",
      "  --force               Force overwrite existing BLAST module output files\n",
      "                        (Default: False, existing output files will not be\n",
      "                        overwritten).\n",
      "  -o OUTPUT_DIR, --output-dir OUTPUT_DIR\n",
      "                        The directory to write the created train-test splits.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "hashFrag create_orthogonal_splits -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381d6c3-0050-401e-87b1-c5b2eb76cc78",
   "metadata": {},
   "source": [
    "# Section 0: Introduction\n",
    "\n",
    "> This notebook refers to the case when users have a nucleotide sequence dataset and are interested in creating homology-aware train-test data splits for sequence-to-expression models.\n",
    "\n",
    "This example workflow is performed on a subsampled MPRA dataset (K562) containing 10,000 sequences (provided in the `data` directory). When calling the `create_orthogonal_splits` pipeline, heuristic alignment scores derived from the `blastn` output are used to define similarity between sequences.\n",
    "\n",
    "Example call of the complete pipeline (`lightning` mode):\n",
    "```\n",
    "hashFrag create_orthogonal_splits \\\n",
    "--fasta-path ../data/example_full_dataset.fa \\\n",
    "--word-size 7 \\\n",
    "--max-target-seqs 10000 \\\n",
    "--evalue 100 \\\n",
    "--threshold 60 \\\n",
    "--n-splits 10 \\\n",
    "--force \\\n",
    "--skip-revcomp \\\n",
    "--output-dir ../data/tutorial.create_orthogonal_splits.work\n",
    "```\n",
    "\n",
    "However, it may be desirable to instead use exact alignment scores (e.g., Smith-Waterman local alignment scores) for the homology search process. This notebook serves as a walkthrough for how users can use manually computed local alignment scores for the BLAST candidate pairs by calling the individual modules comprising the `create_orthogonal_splits` pipeline.\n",
    "\n",
    "## Section 0.1 - A note on the selected parameters for this tutorial \n",
    "\n",
    "Successful identification of cases of homology is paramount to effectively mitigate homology-based data leakage. As such, we configure the BLASTn parameters such that recall is maximized, even if it comes at the expense of increased false-positives. Here we consider the following parameters of BLASTn:\n",
    "\n",
    "* `word_size`: smaller word sizes results in more exact word matches found between the query and sequences in the database, leading to more alignment score calculations being initialized.\n",
    "* `max_target_seqs`: set to the size of the database to remove any constraints and allow for all possible candidate sequences to be returned for a given query.\n",
    "* `evalue`: the e-value statistic is a measure of how likely you observe the alignment by chance (lower value corresponds to less likely to observe). By increasing the e-value threshold, less stringent matches that could be due to chance are returned.\n",
    "* `dust`: by setting dust off, low-complexity (e.g., repetitive sequences) are no longer masked/filtered out.\n",
    "\n",
    "An alignment score threshold of 60 was determined to be appropriate based on an analysis looking at alignment scores between dinucleotide shuffled (i.e., random) sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0deed-41d6-4976-b81c-d2a40d809ba9",
   "metadata": {},
   "source": [
    "# Section 1 - Identifying candidate similar sequences\n",
    "\n",
    "The process of identifying candidate pairs of similar sequences involves first creating a BLAST database of the dataset, and then querying each sequence against the database. The BLASTn algorithm returns pairwise matches that represent potential cases of homology. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc29f5e-cba3-4433-b10b-2f7a3c871292",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:22:22.306632Z",
     "iopub.status.busy": "2025-07-08T05:22:22.306328Z",
     "iopub.status.idle": "2025-07-08T05:28:29.217133Z",
     "shell.execute_reply": "2025-07-08T05:28:29.216402Z",
     "shell.execute_reply.started": "2025-07-08T05:22:22.306615Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-08 14:22:22 - blastn_module - INFO - Calling module...\n",
      "2025-07-08 14:22:22 - blastn_module - INFO - One FASTA files detected. Computing pairwise BLAST comparisons for all sequence-pairs...\n",
      "2025-07-08 14:22:34 - blastn_module - INFO - BLASTn output: \n",
      "\n",
      "Building a new DB, current time: 07/08/2025 14:22:33\n",
      "New DB name:   /rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/hashFrag.blastdb\n",
      "New DB title:  hashFrag\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 10000 sequences in 0.389443 seconds.\n",
      "\n",
      "\n",
      "\n",
      "2025-07-08 14:22:34 - blastn_module - INFO - BLAST DataBase construction finished and written to: /rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/hashFrag.blastdb\n",
      "2025-07-08 14:28:27 - blastn_module - INFO - BLASTn process finished and written to: /rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/hashFrag.blastn.out\n",
      "2025-07-08 14:28:27 - blastn_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "FASTA_PATH=../data/example_full_dataset.fa\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "\n",
    "hashFrag blastn_module \\\n",
    "--fasta-path $FASTA_PATH \\\n",
    "--max-target-seqs 10000 \\\n",
    "--word-size 7 \\\n",
    "--evalue 100 \\\n",
    "--blastdb-label \"hashFrag\" \\\n",
    "--skip-revcomp \\\n",
    "--output-dir $WORK_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7e298-6531-4937-878d-1f1501c4b6b2",
   "metadata": {},
   "source": [
    "## Section 1.1 - Processing raw `blastn` output file\n",
    "\n",
    "This processing step extracts the top-scoring alignment for each unique query-subject sequence pair and corrects the heuristic alignment score for subsequent steps. The processed tab-delimited file contains 3 columns (query sequence ID, subject sequence ID and their corrected heuristic alignment score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c96761f-69de-4557-a7f4-00f99832856a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:34:19.212682Z",
     "iopub.status.busy": "2025-07-08T05:34:19.212350Z",
     "iopub.status.idle": "2025-07-08T05:34:59.121603Z",
     "shell.execute_reply": "2025-07-08T05:34:59.120864Z",
     "shell.execute_reply.started": "2025-07-08T05:34:19.212664Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-08 14:34:56 - process_blast_results_module - INFO - Calling module...\n",
      "2025-07-08 14:34:58 - process_blast_results_module - INFO - Processed BLASTn results written to: ../data/tutorial.create_orthogonal_splits.work/hashFrag.blastn.processed.tsv\n",
      "2025-07-08 14:34:58 - process_blast_results_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "LABEL=hashFrag\n",
    "BLASTN_PATH=$WORK_DIR/${LABEL}.blastn.out\n",
    "PROCESSED_BLASTN_PATH=$WORK_DIR/${LABEL}.blastn.processed.tsv\n",
    "\n",
    "hashFrag process_blast_results_module --blastn-path $BLASTN_PATH --processed-blastn-path $PROCESSED_BLASTN_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d63c8e-42ca-451d-acc0-0f4f336c5f12",
   "metadata": {},
   "source": [
    "# Section 2: Filter false-positives based on a defined threshold\n",
    "\n",
    "The next step involves filtering candidate pairings with alignment scores lower than the specified threshold. There are two different modes of hashFrag depending on what alignment score is selected.\n",
    "\n",
    "1. `hashFrag-lightning` is the faster (and default) version where the alignment score computed from the BLAST output file. BLASTn is a heuristic method and the alignment scores were found to highly correlate with the optimal alignment scores; however, its underestimation of homology in some cases can lead to slightly worse recall. \n",
    "\n",
    "The following call performs the default behavior:\n",
    "```\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "INPUT_PATH=$WORK_DIR/hashFrag.blastn.processed.tsv\n",
    "hashFrag filter_candidates_module -i $INPUT_PATH -t 60 -o $WORK_DIR\n",
    "```\n",
    "\n",
    "2. `hashFrag-pure` is the slower but more comprehensive method that is based on the optimal, Smith-Waterman local alignment scores between pairs of sequences. The calculation of optimal alignment scores incurs an additional cost to filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de3a6b-cfb9-4dac-a41b-3e67e972f9fa",
   "metadata": {},
   "source": [
    "## Section 2.1: hashFrag-pure mode\n",
    "\n",
    "To limit memory usage, we'll start by partitioning the blast output file based on size. \n",
    "\n",
    "After completion of this step, all downstream steps will now be based on the homology identified using the exact alignment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5859ff-f987-4657-9893-5eda20be19a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:37:05.192065Z",
     "iopub.status.busy": "2025-07-08T05:37:05.191715Z",
     "iopub.status.idle": "2025-07-08T05:37:05.391742Z",
     "shell.execute_reply": "2025-07-08T05:37:05.391036Z",
     "shell.execute_reply.started": "2025-07-08T05:37:05.192045Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4.0K\n",
      "-rw-r----- 1 brett 1.2M Jul  8 14:37 hashFrag.blastn.processed.partition_aaah.tsv\n",
      "-rw-r----- 1 brett 3.2M Jul  8 14:37 hashFrag.blastn.processed.partition_aaag.tsv\n",
      "-rw-r----- 1 brett 3.2M Jul  8 14:37 hashFrag.blastn.processed.partition_aaaf.tsv\n",
      "-rw-r----- 1 brett 3.2M Jul  8 14:37 hashFrag.blastn.processed.partition_aaae.tsv\n",
      "-rw-r----- 1 brett 3.2M Jul  8 14:37 hashFrag.blastn.processed.partition_aaad.tsv\n",
      "-rw-r----- 1 brett 3.2M Jul  8 14:37 hashFrag.blastn.processed.partition_aaac.tsv\n",
      "-rw-r----- 1 brett 3.2M Jul  8 14:37 hashFrag.blastn.processed.partition_aaab.tsv\n",
      "-rw-r----- 1 brett 3.2M Jul  8 14:37 hashFrag.blastn.processed.partition_aaaa.tsv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "\n",
    "cd $WORK_DIR\n",
    "PROCESSED_BLASTN_PATH=$PWD/hashFrag.blastn.processed.tsv\n",
    "BLAST_DIR=$PWD/blast_partitions\n",
    "LABEL=$( basename -s \".tsv\" $PROCESSED_BLASTN_PATH )\n",
    "\n",
    "# Create directory for partitioned processed BLAST file\n",
    "mkdir -p $BLAST_DIR\n",
    "cd $BLAST_DIR\n",
    "\n",
    "# Split the file based on number of lines\n",
    "split -l 100000 -a 4 --additional-suffix=.tsv $PROCESSED_BLASTN_PATH ${LABEL}.partition_\n",
    "ls -thor $BLAST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e67396-e139-4544-868b-7b1eeea37b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:37:15.600884Z",
     "iopub.status.busy": "2025-07-08T05:37:15.600556Z",
     "iopub.status.idle": "2025-07-08T05:42:55.199126Z",
     "shell.execute_reply": "2025-07-08T05:42:55.198522Z",
     "shell.execute_reply.started": "2025-07-08T05:37:15.600860Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing exact alignment scores for partitioned files...\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.processed.partition_aaaa.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.processed.partition_aaab.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.processed.partition_aaac.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.processed.partition_aaad.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.processed.partition_aaae.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.processed.partition_aaaf.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.processed.partition_aaag.tsv\n",
      "/rshare1/ZETTAI_path_WA_slash_home_KARA/home/brett/work/OrthogonalTrainValSplits/hashFrag/data/tutorial.create_orthogonal_splits.work/blast_partitions/hashFrag.blastn.processed.partition_aaah.tsv\n",
      "Concatenating partitioned files...\n",
      "BCL11A_1532_Reversed\tpeak24767_Reversed\t14.0\n",
      "BCL11A_1532_Reversed\tBCL11A_976\t17.0\n",
      "BCL11A_1532_Reversed\tENSG00000139330_Reversed\t18.0\n",
      "BCL11A_1532_Reversed\tpeak5045_Reversed\t15.0\n",
      "BCL11A_1532_Reversed\tpeak70281_Reversed\t18.0\n",
      "BCL11A_1532_Reversed\tpeak70514_Reversed\t17.0\n",
      "BCL11A_1532_Reversed\tpeak67427_Reversed\t15.0\n",
      "BCL11A_1532_Reversed\tpeak3273_Reversed\t14.0\n",
      "BCL11A_1532_Reversed\tHBA2_4771_Reversed\t14.0\n",
      "BCL11A_1532_Reversed\tpeak13703\t15.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "DATA_DIR=../data\n",
    "cd $DATA_DIR\n",
    "\n",
    "FASTA_PATH=$PWD/example_full_dataset.fa\n",
    "WORK_DIR=$PWD/tutorial.create_orthogonal_splits.work\n",
    "BLAST_DIR=$WORK_DIR/blast_partitions\n",
    "\n",
    "cd ../src/external\n",
    "\n",
    "echo \"Computing exact alignment scores for partitioned files...\"\n",
    "for PARTITIONED_BLAST_PATH in $BLAST_DIR/*.partition_*.tsv\n",
    "do\n",
    "    echo $PARTITIONED_BLAST_PATH\n",
    "    bash compute_blast_candidate_SW_scores.sh $FASTA_PATH $PARTITIONED_BLAST_PATH\n",
    "done\n",
    "\n",
    "echo \"Concatenating partitioned files...\"\n",
    "cat $BLAST_DIR/*.pairwise_scores.tsv > $WORK_DIR/hashFrag_pure.blastn_candidates.sw_scores.tsv\n",
    "cat $WORK_DIR/hashFrag_pure.blastn_candidates.sw_scores.tsv | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c8e40c2-0972-4413-9201-37fbf60e124b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:43:28.103123Z",
     "iopub.status.busy": "2025-07-08T05:43:28.102673Z",
     "iopub.status.idle": "2025-07-08T05:43:28.105775Z",
     "shell.execute_reply": "2025-07-08T05:43:28.105409Z",
     "shell.execute_reply.started": "2025-07-08T05:43:28.103102Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "# INPUT_PATH=$WORK_DIR/hashFrag_pure.blastn_candidates.sw_scores.tsv\n",
    "# hashFrag filter_candidates_module -i $INPUT_PATH -t 60 -o $WORK_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c75343-485f-441c-9576-e4c61b82ccb0",
   "metadata": {},
   "source": [
    "# Section 3: Determine groups of homology\n",
    "\n",
    "There are often distinct groups of sequences exhibiting different cases of homology throughout the dataset. To determine such groups, we represent the \"hits\" (i.e., pairs of sequences with an alignment score greater than the threshold) as a sparse adjacency matrix. A graph can then be constructed, where nodes correspond to sequences and edges denote shared homology between the two sequences. The process of identifying groups of homology can readily be solved by identifying disconnected subgraphs. \n",
    "\n",
    "An efficient implementation for this graph-based task is provided in the `igraph` Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6f54fd6-7039-4304-95eb-2bf5974bef81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:48:20.258580Z",
     "iopub.status.busy": "2025-07-08T05:48:20.258079Z",
     "iopub.status.idle": "2025-07-08T05:48:41.351361Z",
     "shell.execute_reply": "2025-07-08T05:48:41.350637Z",
     "shell.execute_reply.started": "2025-07-08T05:48:20.258555Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-08 14:48:37 - identify_homologous_groups_module - INFO - Calling module...\n",
      "2025-07-08 14:48:40 - identify_homologous_groups_module - INFO - 4523 distinct groups.\n",
      "2025-07-08 14:48:40 - identify_homologous_groups_module - INFO - Homologous groups written to: ../data/tutorial.create_orthogonal_splits.work/homologous_groups.pure.csv\n",
      "2025-07-08 14:48:40 - identify_homologous_groups_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "hashFrag identify_homologous_groups_module -i $WORK_DIR/hashFrag_pure.blastn_candidates.sw_scores.tsv -t 60 -o $WORK_DIR/homologous_groups.pure.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5565f51-e041-490a-a639-519dff059526",
   "metadata": {},
   "source": [
    "# Section 4: Use case(s)\n",
    "\n",
    "Upon identifying groups of sequences exhibiting high similarity (i.e., homology), we can create train-test data splits using a graph-based method. Specifically, by representing sequences as nodes and using edges to denote whether sequences were found to be homologous (yes or no), identifying homologous groups of sequences can be reduced to the task of identifying all disconnected subgraphs in the population. \n",
    "\n",
    "## Creating homology-aware data splits\n",
    "\n",
    "Below we show how splits can be created based on the homologous groups identified from either the `hashFrag-lightning` or `hashFrag-pure` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8b8f59f-0c8b-4118-a4b9-1e4962996887",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:49:27.107807Z",
     "iopub.status.busy": "2025-07-08T05:49:27.107336Z",
     "iopub.status.idle": "2025-07-08T05:49:27.836546Z",
     "shell.execute_reply": "2025-07-08T05:49:27.835966Z",
     "shell.execute_reply.started": "2025-07-08T05:49:27.107786Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-08 14:49:27 - create_orthogonal_splits_module - INFO - Calling module...\n",
      "2025-07-08 14:49:27 - create_orthogonal_splits_module - INFO - Creating 10 orthogonal splits in directory: ../data/tutorial.create_orthogonal_splits.work\n",
      "2025-07-08 14:49:27 - create_orthogonal_splits_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "HOMOLOGY_PATH=$WORK_DIR/homologous_groups.pure.csv # pure mode\n",
    "OUT_DIR=$WORK_DIR\n",
    "hashFrag create_orthogonal_splits_module -i $HOMOLOGY_PATH -n 10 -o $OUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e80e64-4d8f-47d6-a911-0471f2d907fe",
   "metadata": {},
   "source": [
    "# Creating homology-aware data folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49947f66-ab8b-4303-afa5-81c3648f723a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:53:44.723464Z",
     "iopub.status.busy": "2025-07-08T05:53:44.723011Z",
     "iopub.status.idle": "2025-07-08T05:53:45.123020Z",
     "shell.execute_reply": "2025-07-08T05:53:45.122625Z",
     "shell.execute_reply.started": "2025-07-08T05:53:44.723443Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: hashFrag create_orthogonal_folds_module [-h] -i HOMOLOGY_PATH\n",
      "                                               [-f FOLDS] [-s SEED] -o\n",
      "                                               OUTPUT_DIR\n",
      "\n",
      "Given the clustering of sequences based on homology\n",
      "('identify_homologous_groups'), create homology-aware folds. Homologous groups\n",
      "are defined as disjoint sets over the population of sequences.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -i HOMOLOGY_PATH, --homology-path HOMOLOGY_PATH\n",
      "                        The tab-delimited file containing the homologous group\n",
      "                        labels that the relevant sequences in the test split\n",
      "                        belong to (output file of\n",
      "                        'identify_homologous_groups').\n",
      "  -f FOLDS, --folds FOLDS\n",
      "                        Number of folds to create.\n",
      "  -s SEED, --seed SEED  Random seed to use for the creation of homology-aware\n",
      "                        data splits (Default 21).\n",
      "  -o OUTPUT_DIR, --output-dir OUTPUT_DIR\n",
      "                        The directory to write the created train-test splits.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "hashFrag create_orthogonal_folds_module -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e2afabc-6959-4b01-a34a-107572afbdd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T05:53:48.176715Z",
     "iopub.status.busy": "2025-07-08T05:53:48.176282Z",
     "iopub.status.idle": "2025-07-08T05:53:48.541728Z",
     "shell.execute_reply": "2025-07-08T05:53:48.541335Z",
     "shell.execute_reply.started": "2025-07-08T05:53:48.176696Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-08 14:53:48 - create_orthogonal_folds_module - INFO - Calling module...\n",
      "2025-07-08 14:53:48 - create_orthogonal_folds_module - WARNING - There exist(s) homologous groups of larger size than the expected fold size. Resulting folds may be imbalanced!\n",
      "2025-07-08 14:53:48 - create_orthogonal_folds_module - INFO - Creating 10 orthogonal folds...\n",
      "2025-07-08 14:53:48 - create_orthogonal_folds_module - INFO - Orthogonal folds written to ../data/tutorial.create_orthogonal_splits.work/hashFrag.10_orthogonal_folds.tsv\n",
      "2025-07-08 14:53:48 - create_orthogonal_folds_module - INFO - Module execution completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "WORK_DIR=../data/tutorial.create_orthogonal_splits.work\n",
    "HOMOLOGY_PATH=$WORK_DIR/homologous_groups.pure.csv # pure mode\n",
    "OUT_DIR=$WORK_DIR\n",
    "hashFrag create_orthogonal_folds_module -i $HOMOLOGY_PATH -f 10 -o $OUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b954f6-7978-47dc-9e17-b782f1d61f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
